{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fitted-miniature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import signal\n",
    "import pywt\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import pickle\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from platform import python_version\n",
    "print(python_version())\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-sunglasses",
   "metadata": {},
   "source": [
    "# Read and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "demanding-delight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(accDir, annotFile):\n",
    "    files = os.listdir(accDir)\n",
    "    files_csv = [f for f in files if f[-3:] == 'csv']\n",
    "    empatica_dict = dict()\n",
    "    for f in files_csv:\n",
    "        data = np.genfromtxt(accDir+f, delimiter=',') # creates numpy array for each Empatica acc csv file\n",
    "        key = int(float(f.strip(\"ACC.csv\")))\n",
    "        empatica_dict[key] = data\n",
    "    tmp = pd.read_excel(annotFile, sheet_name=None)\n",
    "    annot_dict = dict(zip(tmp.keys(), [i.dropna() for i in tmp.values()])) # Remove the rows with NaN values (some with ladder 2 missing)\n",
    "    return empatica_dict, annot_dict\n",
    "\n",
    "def getLabeledDict(empatica_dict, annot_dict, subject_ids, SR):\n",
    "    labeled_dict = {}; taskInd_dict = {}\n",
    "    for id in subject_ids:\n",
    "        start_time = int(empatica_dict[id][0,0])\n",
    "        acc = empatica_dict[id][2:,:]\n",
    "        label = list(map(lambda i: i.replace(\"_end\", \"\").replace(\"_start\", \"\"), annot_dict['P'+ str(id)].taskName.tolist()))\n",
    "        task_time= list(map(lambda i: time.mktime(datetime.datetime.strptime(i[:6] + '20' + i[6:], \"%m/%d/%Y %H:%M:%S\").timetuple()),\n",
    "                            annot_dict['P'+ str(id)].startTime_global.tolist()))\n",
    "        task_ind = [int(x - start_time)*SR for x in task_time]\n",
    "        taskInd_dict[id] = task_ind\n",
    "        label_tmp = np.empty(acc.shape[0], dtype=object)\n",
    "        for i, (j, k) in enumerate(zip(task_ind[0::2], task_ind[1::2])):\n",
    "            tmpInd = 2*i\n",
    "            label_tmp[j:k] = label[tmpInd]\n",
    "        acc_mag = np.sqrt(np.sum(acc**2, axis=1))[:,None]\n",
    "        accel = np.hstack((acc, acc_mag))\n",
    "        labeled_dict[id] = pd.DataFrame(np.hstack((accel, label_tmp.reshape(label_tmp.shape[0],1))), columns=['X', 'Y', 'Z', 'Mag', 'label'])\n",
    "    return labeled_dict, taskInd_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "junior-dietary",
   "metadata": {},
   "outputs": [],
   "source": [
    "sepAccDict, sepAnnotDict = readData(accDir='./Data/Acc Data/', annotFile='./Data/Annotation Data/separate.xlsx')\n",
    "SR=int(sepAccDict[8][1,0])\n",
    "\n",
    "sepSubIDs = list(range(8,45))\n",
    "sepLabeledDict_, sepTaskIndDict = getLabeledDict(sepAccDict, sepAnnotDict, sepSubIDs, SR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-dispatch",
   "metadata": {},
   "source": [
    "## Apply Low Pass Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "treated-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Filter on All Subjects\n",
    "n=4; fc=2; w=fc/(SR/2)\n",
    "b, a = signal.butter(n, w, 'low')\n",
    "sepLabeledDict_filtered = dict(map(lambda key: (key, signal.filtfilt(b, a, x=sepLabeledDict_[key].drop(columns='label'), axis=0)), sepLabeledDict_.keys()))\n",
    "# back to DF and add label\n",
    "sepLabeledDict_filtered_dfs = dict(map(lambda key: (\n",
    "                                                        key, pd.DataFrame(sepLabeledDict_filtered[key],columns=['X', 'Y', 'Z', 'Mag']).assign(label=sepLabeledDict_[key].label)\n",
    "                                                    ), sepLabeledDict_filtered.keys()))\n",
    "# Remove data without label\n",
    "filt_noNA_dict = dict(map(lambda key: (key, sepLabeledDict_filtered_dfs[key].dropna()), sepLabeledDict_filtered_dfs.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-vanilla",
   "metadata": {},
   "source": [
    "# Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bizarre-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model('trained_model/tf_model/')\n",
    "test_subs = pd.read_pickle('trained_model/test_subs.pickle')\n",
    "history = pd.read_pickle('trained_model/keras_history.pickle')\n",
    "scaler = pd.read_pickle('trained_model/scaler.pickle')\n",
    "labels_categorical = ['sit', 'stand', 'walk', 'hoist', 'lift', 'push', 'type', 'ladder', 'electricPanel', 'overhead']\n",
    "labels_encoded = LabelEncoder().fit_transform(labels_categorical).tolist()\n",
    "labels_dict = dict([(numeric_, categorical_) for numeric_, categorical_ in zip(labels_encoded, labels_categorical)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-suffering",
   "metadata": {},
   "source": [
    "## Activity Classification on Test (Unseen) Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bronze-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwt_dict = {}\n",
    "label_dict = {}\n",
    "for sub in sorted(test_subs):\n",
    "    tasks = ['sit', 'stand', 'walk', 'hoist', 'lift', 'push', 'type', 'ladder1', 'ladder2', 'electricPanel', 'overhead']\n",
    "    sig_ = filt_noNA_dict[sub]\n",
    "    sig = sig_[sig_.label.isin(tasks)]\n",
    "    winLen = 320\n",
    "    scales = range(1,200)\n",
    "    waveletname = 'morl'\n",
    "    cwt_list = []\n",
    "    label_dict[sub] = []\n",
    "    for label, label_df in sig.groupby(by='label'):\n",
    "        for window, window_df in label_df.groupby(by=np.arange(label_df.shape[0])//winLen):\n",
    "            if window_df.shape[0] == winLen:\n",
    "                label_dict[sub].append(label)\n",
    "                ########### cwt transform\n",
    "                tmp = np.zeros((max(scales), winLen, 3))\n",
    "                for i in range(3):\n",
    "                    tmp_sig = window_df.values[:,i]\n",
    "                    coeff, freq = pywt.cwt(tmp_sig, scales, waveletname, 1/SR)\n",
    "                    tmp[:,:,i] = coeff\n",
    "                cwt_list.append(tmp)\n",
    "    cwt_dict[sub] = np.array(cwt_list)\n",
    "    label_dict[sub] = [elem.replace(\"1\", \"\").replace(\"2\", \"\") for elem in label_dict[sub]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "filled-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels_dict = {}\n",
    "true_pred_dict = {}\n",
    "for sub in sorted(test_subs):\n",
    "    ############## predict label\n",
    "#     scaler = np.max(cwt_dict[sub])\n",
    "    pred_labels_dict[sub] = {}\n",
    "    pred_label = model.predict(cwt_dict[sub]/scaler)\n",
    "    numeric_pred = np.argmax(pred_label, axis=1)\n",
    "    pred_labels_dict[sub] = [labels_dict[elem] for elem in numeric_pred]\n",
    "    true_pred_dict[sub] = pd.DataFrame({'true': label_dict[sub], 'predicted': pred_labels_dict[sub]})\n",
    "################### Store Reports\n",
    "report_df_dict = {}\n",
    "acc = {}\n",
    "for sub in sorted(test_subs):\n",
    "    report_dict = classification_report(true_pred_dict[sub].true, true_pred_dict[sub].predicted, output_dict=True)\n",
    "    report_df_dict[sub] = pd.DataFrame(report_dict).drop(columns=['macro avg', 'weighted avg'], index='support').round(decimals=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-private",
   "metadata": {},
   "source": [
    "# Results\n",
    "## Plot Confusion Matrix for Each Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "engaging-christmas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d53650eb82724f349e0b797c6df5a96b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output(), Output(), Output(), Output(), Output(), Output()), _titles={'0': 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_tab = [widgets.Output() for i in range(len(test_subs))]\n",
    "tab = widgets.Tab(sub_tab)\n",
    "for i, sub in enumerate(sorted(test_subs)):\n",
    "    tab.set_title(i, 'Subject ' + str(sub))\n",
    "    with sub_tab[i]:\n",
    "        cm = confusion_matrix(true_pred_dict[sub].true, true_pred_dict[sub].predicted)#, labels=true_pred_dict[sub].true.unique())\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=true_pred_dict[sub].true.unique())\n",
    "        fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "        disp.plot(ax=ax, cmap=plt.cm.Blues)\n",
    "        plt.show()\n",
    "        display(report_df_dict[sub])\n",
    "display(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-dealer",
   "metadata": {},
   "source": [
    "## Export Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-formula",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = 8\n",
    "cm = confusion_matrix(true_pred_dict[sub].true, true_pred_dict[sub].predicted, labels=true_pred_dict[sub].true.unique())\n",
    "df_cm = pd.DataFrame(cm, index=true_pred_dict[sub].true.unique(), columns=true_pred_dict[sub].true.unique())\n",
    "df_cm.to_csv('./outputs/CNN classification/cm_19.csv')\n",
    "df_cm = df_cm.rename(columns={'electricPanel':'EP', 'hoist':'H', 'ladder':'Ld', 'lift':'Lf', 'overhead':'OH', 'push':'P', 'sit':'St', 'stand':'Sd', 'type':'Tp', 'walk':'W'},\n",
    "             index={'electricPanel':'EP', 'hoist':'H', 'ladder':'Ld', 'lift':'Lf', 'overhead':'OH', 'push':'P', 'sit':'St', 'stand':'Sd', 'type':'Tp', 'walk':'W'})\n",
    "\n",
    "f, ax = plt.subplots(1, figsize=(7,7))\n",
    "sn.heatmap(df_cm, cmap=plt.cm.Blues, annot=True, cbar=False, annot_kws={\"fontsize\":20})\n",
    "ax.tick_params(axis='both', labelsize=20)\n",
    "ax.tick_params(axis='y', rotation=0)\n",
    "ax.set_ylabel('True Label', fontsize=20)\n",
    "ax.set_xlabel('Predicted Label', fontsize=20)\n",
    "ax.set_title( 'Confusion Matrix', fontsize=25)\n",
    "f.tight_layout(pad=0.1)\n",
    "f.savefig('./outputs/cnf_mtrx/cnf ' + str(sub) + '.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-europe",
   "metadata": {},
   "source": [
    "## Export Subject-specific Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "rapid-spirituality",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in report_df_dict.keys():\n",
    "    report_df_dict[sub].to_csv('./outputs/CNN classification/' + str(sub) + '.csv')\n",
    "    \n",
    "report_df_dict[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-narrow",
   "metadata": {},
   "source": [
    "## Overal Test Subject Accuracy Excluding The Left-handed Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "friendly-sharp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9642160052049447\n"
     ]
    }
   ],
   "source": [
    "true_pred_dict_list = [true_pred_dict[key] for key in true_pred_dict.keys() if key!=19]\n",
    "test_true_pred_df = pd.concat(true_pred_dict_list, ignore_index=True)\n",
    "overall_test_acc = accuracy_score(test_true_pred_df.true, test_true_pred_df.predicted)\n",
    "print(overall_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-puzzle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-orchestra",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
